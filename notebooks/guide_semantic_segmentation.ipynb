{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a112eb1",
   "metadata": {},
   "source": [
    "## Semantic Segmentation with Masterful \n",
    "\n",
    "In this guide we will walk you through the steps on how to use the Masterful AutoML platform to train a model on the task of semantic segmentation. \n",
    "\n",
    "This guide is inspired by the Tensorflow [Image Segmentation](https://www.tensorflow.org/tutorials/images/segmentation) guide. We use the same dataset ([Oxford IIIT Pets](https://www.robots.ox.ac.uk/~vgg/data/pets/)) and model (a modified [U-Net](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)) as that guide, so that you can see the side-by-side comparison between training with and without Masterful.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/masterfulai/masterful-docs/blob/main/notebooks/guide_semantic_segmentation.ipynb)\n",
    "[![download button](https://www.tensorflow.org/images/download_logo_32px.png)](https://masterful-public.s3.us-west-1.amazonaws.com/933013963/latest/guide_semantic_segmentation.ipynb) Download this Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12606b2",
   "metadata": {},
   "source": [
    "### Import the Necessary Libraries\n",
    "\n",
    "In this Guide, we will be using Tensorflow as the training infrastructure, and Tensorflow Datasets to provide the training data. We use Keras on top of Tensorflow to help us build the model, and since we are using the same model as the [Image Segmentation](https://www.tensorflow.org/tutorials/images/segmentation) guide, we have a few imports to pull in the model definition from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e03154d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# We use Keras to build the individual model layers\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c691d04",
   "metadata": {},
   "source": [
    "### Register Masterful\n",
    "\n",
    "Registration is necessary to ensure you have a valid authorization key and are licensed to use the Masterful AutoML platform. Make sure to fill in the `<INSERT HERE>` sections with the account ID and authorization key provided to you by Masterful AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aba6e916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASTERFUL: Your account has been successfully registered. Masterful v0.3.6 is loaded.\n"
     ]
    }
   ],
   "source": [
    "MASTERFUL_ACCOUNT_ID=\"<INSERT HERE>\"\n",
    "MASTERFUL_AUTHORIZATION_KEY=\"<INSERT HERE>\"\n",
    "\n",
    "import masterful\n",
    "masterful = masterful.register(account_id=MASTERFUL_ACCOUNT_ID, authorization_key=MASTERFUL_AUTHORIZATION_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd9d13e",
   "metadata": {},
   "source": [
    "### Prepare the Dataset\n",
    "\n",
    "The dataset is available from [TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/oxford_iiit_pet). The segmentation masks are included in version 3+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74637e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (128, 128, 3)\n",
    "dataset_splits, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True, split=['train', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b1f23f",
   "metadata": {},
   "source": [
    "Tensorflow Datasets returns a dictionary of features for each example, but Masterful requires an explicit (image, label) tuple for input examples, similar to the input you would provide to Keras [model.fit()](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit), for example. Therefore, the first task is to extract the image and label (in this case the segmentation mask) from the feature dictionary.\n",
    "\n",
    "After the image and label has been extracted, we need to standardize the data for the model we are using. In this case, the U-Net model we have chosen expects each input image to be in a square format. In addition, the image color space should be RGB floats in the range [0,1].\n",
    "\n",
    "Finally, we need to create the labels (segmentation masks) we will use for supervised training. The Oxford Pets dataset consists of images of 37 pet breeds, with 200 images per breed (~100 each in the training and test splits). Each image includes the corresponding labels, and pixel-wise masks. The masks are class-labels for each pixel. Each pixel is given one of three categories:\n",
    "\n",
    "- Class 1: Pixel belonging to the pet.\n",
    "- Class 2: Pixel bordering the pet.\n",
    "- Class 3: None of the above/a surrounding pixel. \n",
    "\n",
    "For convenience, we will convert the class labels from [1,2,3] to [0,1,2] similar to the [Image Segmentation](https://www.tensorflow.org/tutorials/images/segmentation) guide, and we will then convert them to one-hot class labels, because Masterful performs better with dense rather than sparse labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9242a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_and_label(features):\n",
    "  \"\"\" \n",
    "  Extracts the image and segmentation mask from the feature dictionary,\n",
    "  and applies minimal normalization (resizing and label standardization).\n",
    "  \"\"\"\n",
    "  image = tf.image.resize(features['image'], (INPUT_SHAPE[0], INPUT_SHAPE[1]))\n",
    "  mask = tf.image.resize(features['segmentation_mask'], (INPUT_SHAPE[0], INPUT_SHAPE[1]))\n",
    "\n",
    "  # Convert the image into the [0,1] RGB color space.\n",
    "  image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "  # For convenience, convert the segmentation mask into \n",
    "  # [0,1,2] class labels.\n",
    "  mask -= 1\n",
    "\n",
    "  # Convert to one-hot labels in the mask.\n",
    "  mask = tf.one_hot(tf.cast(tf.squeeze(mask, axis=-1), tf.int32), depth=3)      \n",
    "  return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dfd3b2",
   "metadata": {},
   "source": [
    "Make sure to apply the `extract_image_and_label` function to both the training and test datasets, so that model training and evaluation both see the same input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd5c20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_dataset = dataset_splits[0]\n",
    "test_dataset = dataset_splits[1]\n",
    "\n",
    "labeled_dataset = labeled_dataset.map(extract_image_and_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(extract_image_and_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# The Oxford Pets dataset on TF Datasets contains a few corrupted images,\n",
    "# as well as several images that do not decode correctly. We apply\n",
    "# the ignore_errors() operator here to eliminate the annoying warnings\n",
    "# that will show up in the console due to these errors.\n",
    "labeled_dataset = labeled_dataset.apply(tf.data.experimental.ignore_errors())\n",
    "test_dataset = test_dataset.apply(tf.data.experimental.ignore_errors())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db9a163",
   "metadata": {},
   "source": [
    "### Define the Model (U-Net)\n",
    "\n",
    "The model being used here is a modified [U-Net](https://arxiv.org/abs/1505.04597). A U-Net consists of an encoder (downsampler) and decoder (upsampler). In this guide, we are using a very simple encoder/decoder architecture, to demonstrate the principles of using Masterful. This model should not be used in a production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9f5b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_unet(input_shape):\n",
    "  \"\"\"\n",
    "  Creates a simple UNet encoder-decoder architecture, with a\n",
    "  3 channel output (logits based) for semantic segmentation.\n",
    "  Assumes an input/output size of (128,128).\n",
    "  \"\"\"\n",
    "\n",
    "  def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "  def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "  def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "  inputs = Input(input_shape)\n",
    "\n",
    "  s1, p1 = encoder_block(inputs, 32)\n",
    "  s2, p2 = encoder_block(p1, 64)\n",
    "  s3, p3 = encoder_block(p2, 128)\n",
    "  s4, p4 = encoder_block(p3, 128)\n",
    "\n",
    "  b1 = conv_block(p4, 128)\n",
    "\n",
    "  d1 = decoder_block(b1, s4, 128)\n",
    "  d2 = decoder_block(d1, s3, 128)\n",
    "  d3 = decoder_block(d2, s2, 64)\n",
    "  d4 = decoder_block(d3, s1, 32)\n",
    "\n",
    "  outputs = Conv2D(3, 1, padding=\"same\")(d4)\n",
    "  model = Model(inputs, outputs, name=\"U-Net\")\n",
    "  return model\n",
    "model = simple_unet(INPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dd89fe",
   "metadata": {},
   "source": [
    "### Train the Model.\n",
    "\n",
    "The first step when using Masterful is to specify some design choices about your model by using `masterful.spec.create_model_and_data_specs`. Masterful tries to infer as much as possible about your model and dataset, but for things which cannot be inferred, Masterful has created `masterful.ModelSpec` and `masterful.DataSpec` data structures to inform the platform about these choices. \n",
    "\n",
    "In the example below, we are letting Masterful know that we are performing a semantic segmentation task (`masterful.spec.Task.SEMANTIC_SEGMENTATION`) with 3 class labels (`num_classes=3`), and that our input image features are in the range [0,1] (`image_range=masterful.spec.ImageRange.ZERO_ONE`). Furthermore, we are providing dense labels (`sparse=False`) and that our model is outputting logits rather than a softmax classification (`from_logits=True`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43ef4f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spec, data_spec = masterful.spec.create_model_and_data_specs(\n",
    "    model=model,\n",
    "    dataset=labeled_dataset,\n",
    "    task=masterful.spec.Task.SEMANTIC_SEGMENTATION,\n",
    "    image_range=masterful.spec.ImageRange.ZERO_ONE,\n",
    "    num_classes=3,\n",
    "    sparse=False,\n",
    "    from_logits=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aff75fa",
   "metadata": {},
   "source": [
    "Now, you are ready to train your model using the Masterful AutoML platform. In the next cell, you will see the call to `masterful.autofit`, which is the entry point to the meta-learning engine of the Masterful AutoML platform. Notice there is no need to batch your data (Masterful will find the optimal batch size for you). No need to shuffle your data (Masterful handles this for you). You don't even need to pass in a validation dataset (Masterful finds one for you). You hand Masterful a model and a dataset, and Masterful will figure the rest out for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e72a2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASTERFUL: Auto-fitting model to datasets.\n",
      "...\n",
      "MASTERFUL: Training complete in 13.6272061546643575 minutes.\n"
     ]
    }
   ],
   "source": [
    "fit_policy, fit_report = masterful.autofit(\n",
    "  model, \n",
    "  model_spec, \n",
    "  labeled_dataset, \n",
    "  data_spec,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d130f70e",
   "metadata": {},
   "source": [
    "The model you passed into `masterful.autofit` is now trained and updated in place, so you are able to evaluate it just like any other trained Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6702ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 3s 49ms/step - loss: 0.2624 - categorical_accuracy: 0.9003\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(test_dataset.batch(fit_policy.batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterful_release_testing",
   "language": "python",
   "name": "masterful_release_testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
